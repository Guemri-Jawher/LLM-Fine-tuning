# LLM Fine-Tuning Project

This repository contains Jupyter notebooks demonstrating various techniques for fine-tuning Large Language Models (LLMs) using popular frameworks and datasets.

## Contents

- **Fine_tune_Llama_2.ipynb**  
  Fine-tuning Llama 2 models.

- **Fine_Tuning_LLm_Models_Gradient_ai.ipynb**  
  Fine-tuning LLMs using Gradient AI.

- **Fine_Tuning_with_Mistral_QLora_PEFt.ipynb**  
  Fine-tuning with Mistral, QLora, and PEFT.

- **lora_tuning_Gemma_2b_en.ipynb**  
  LoRA fine-tuning for Gemma 2B using KerasNLP and the Databricks Dolly 15k dataset.

## Main Features

- Step-by-step guides for setting up environments and dependencies.
- Instructions for downloading and preprocessing datasets.
- Examples of LoRA, QLora, and PEFT fine-tuning methods.
- Inference examples before and after fine-tuning.
- Evaluation and comparison of model outputs.

## Requirements

- Python 3.8+
- Jupyter Notebook
- Keras, KerasNLP, GradientAI, Mistral, QLora, PEFT (see individual notebooks for installation commands)
- Sufficient GPU resources (recommended for large models)

## Getting Started

1. Clone the repository.
2. Open any notebook in Jupyter or Colab.
3. Follow the setup instructions in each notebook to install dependencies and configure your environment.
4. Run the cells to fine-tune and evaluate models.

## References

- [Gemma Models Documentation](https://ai.google.dev/gemma/docs/lora_tuning)
- [Databricks Dolly 15k Dataset](https://huggingface.co/datasets/databricks/databricks-dolly-15k)
- [KerasNLP](https://keras.io/api/keras_nlp/models/)
- [Gradient AI](https://www.gradient.ai/)
- [PEFT](https://github.com/huggingface/peft)
